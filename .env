# Ollama Model Configuration
# MODEL_NAME=tinyllama

# API Configuration (optional)
# HOST=0.0.0.0
# PORT=8000

# Add other environment variables as needed
# API_KEY=your-api-key-here


USE_MOCK_LLM=1

